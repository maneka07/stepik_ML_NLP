{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85caade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tatiana\\anaconda3\\envs\\NlpEnv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tatiana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb87e3bd",
   "metadata": {},
   "source": [
    "***\n",
    "The data file has four news articles, three of them are about the Tesla Roadster car in space and the fourth is about a different topic (a gas company). I want to check the similarity of the four articles using cosine similarity and Eulcidean distance using different vector representations of words. \n",
    "Will follow the article https://towardsdatascience.com/calculating-document-similarities-using-bert-and-other-models-b2c1a29c9630. \n",
    "The expectation is that the first three articles will be assessed as similar, while the fourth one different from them all.\n",
    "\n",
    "A nice article on the interpretation of cosine similarity and Euclidean distance\n",
    "https://www.baeldung.com/cs/euclidean-distance-vs-cosine-similarity\n",
    "Cosine similarity is a metric used to measure how similar the documents are irrespective of their size. The cosine similarity is advantageous because even if the two similar documents are far apart by the Euclidean distance (due to the size of the document), chances are they may still be oriented closer together. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2863d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/roadster_news.csv', header=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f977480d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Электрокар Tesla Roadster Илона Маска, запущен...\n",
       "1    Прошло почти четыре года с тех пор, как Илон М...\n",
       "2    Tesla преодолела более трех миллиардов километ...\n",
       "3    «Газпром» снизит поставки газа через «Северный...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab1174",
   "metadata": {},
   "source": [
    "***\n",
    "First, let's compute cosine similarity and ED using the Tf-Idf matrix\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5948dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=nltk.corpus.stopwords.words('russian'), \n",
    "                             token_pattern=r'\\b[^\\d\\W]{4,20}\\b') #\"\\b[a-zA-z]+'?[a-zA-Z]+'\\b\",\n",
    "tfidf_mat = vectorizer.fit_transform(data)              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c50fd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosi = [] #cosine similarity\n",
    "ed = [] #euclidean distance\n",
    "for r1, r2 in itertools.combinations(range(tfidf_mat.shape[0]), 2):\n",
    "    c = np.dot(tfidf_mat[r1], tfidf_mat[r2].T).toarray()[0][0]\n",
    "    d = np.sqrt((tfidf_mat[r2] - tfidf_mat[r1]).power(2).sum())\n",
    "    cosi.append((r1, r2, c))\n",
    "    ed.append((r1, r2, d))\n",
    "#\n",
    "#ed = euclidean_distances(tfidf_mat)\n",
    "#cosine_similarity(tfidf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a546268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar texts are 1 and 2 (cosine similarity is 0.34236235938013404 ):\n",
      "Прошло почти четыре года с тех пор, как Илон Маск запустил свой Tesla Roadster в космос на ракете Falcon Heavy компании SpaceX. Сейчас электромобиль находится на таком расстоянии от Земли, что Марс ему куда ближе родной планеты. Вскоре после запуска электрокара в космос был запущен и сайт Where is Roadster? для отслеживания его перемещения с помощью данных NASA. Ресурс указывает, что Roadster удаляется от Земли со скоростью 6 005 км/ч, в то время как к Марсу он движется со скоростью 27 955 км/ч. До Красной планеты осталось менее 320 миллионов км, а общий \"пробег\" машины почти достиг 3 млрд километров. Этого достаточно, чтобы проехать по всем дорогам мира 49,5 раз. В беседе CNN с астрономом Джонатаном Макдауэллом из Гарвард-Смитсоновского центра астрофизики выяснилось, что Tesla, вероятно, всё ещё цела, но могла быть повреждена ударами метеоритов. Интересно, что астрономы не наблюдали электромобиль в свои телескопы с марта 2018 года, а профессор астрофизики Университета Торонто Ханно Рейн заявил, что изучение его траектории не имеет особой научной ценности. В конце концов, это не более чем дорогой космический мусор.\n",
      "-\n",
      "Tesla преодолела более трех миллиардов километров. В космосе Электромобилю для этого потребовалось четыре года. С тех пор, как Илон Маск запустил красную Tesla Roadster в космос на ракете Falcon Heavy своей компании SpaceX, прошло четыре года. В настоящее время электрокар находится уже ближе к Марсу, чем к Земле — от нашей планеты он удалился на 377 миллионов километров. После запуска родстера в космос был запущен сайт Where is Roadster? для отслеживания его перемещения при помощи NASA. Согласно официальным данным, всего Tesla преодолела уже более 3,2 миллиарда километров.\n"
     ]
    }
   ],
   "source": [
    "cosi.sort(key=lambda v:v[2], reverse=True)\n",
    "print(f'Most similar texts are {cosi[0][0]} and {cosi[0][1]} (cosine similarity is {cosi[0][2]} ):')\n",
    "print(data[cosi[0][0]])\n",
    "print('-')\n",
    "print(data[cosi[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb2bbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least similar texts are 0 and 3 (cosine similarity is 0.00434486639530668 ):\n",
      "Электрокар Tesla Roadster Илона Маска, запущенный в сторону Марса в начале 2018 года, постепенно разрушается в открытом космосе. К таким выводам пришли эксперты издания LiveScience. По их данным, автомобиль уже полностью лишился окраски кузова, кожаных сидений и покрышек.По словам химика из университета Индианы и эксперта по пластмассам и органическим молекулам Уильяма Кэрролла, в будущем от машины останутся лишь каркас и стекла. На молекулы распадутся и все пластиковые детали электрокара. Месяц назад машину уже официально признали космическим мусором — автомобиль был внесен в соответствующий каталог всех космических объектов искусственного происхождения (GCAT). Напомним, электрокар Tesla Roadster первого поколения, принадлежащий главе компаний Tesla и SpaceX Илону Маску, отправили в космос на ракете-носителе Falcon Heavy. Машина выступила в качестве балластной нагрузки, призванной продемонстрировать грузоподъемность космического корабля. За рулем автомобиля сидел манекен в скафандре, которого назвали Starman, а при запуске ракеты из динамиков авто играла песня Дэвида Боуи Space Oddity.\n",
      "-\n",
      "«Газпром» снизит поставки газа через «Северный поток-1» из-за задержки с ремонтом агрегатов компанией Siemens, сообщила госкомпания. «Поставки газа в газопровод «Северный поток» в настоящее время могут быть обеспечены в объеме до 100 млн куб. м в сутки (при плановом объеме 167 млн куб. м в сутки)», — заявили в компании. В «Газпроме» пояснили, что сокращение поставок связано с ситуацией на компрессорной станции (КС) «Портовая». По данным оператора, немецкая компания Siemens несвоевременно вернула газоперекачивающие агрегаты из ремонта. Кроме того, проблемы связаны с выработкой межремонтного ресурса газоперекачивающих агрегатов и выявленными техническими неисправностями двигателей (получено предписание Ростехнадзора о временном запрете деятельности).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Least similar texts are {cosi[-1][0]} and {cosi[-1][1]} (cosine similarity is {cosi[-1][2]} ):')\n",
    "print(data[cosi[-1][0]])\n",
    "print('-')\n",
    "print(data[cosi[-1][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b998720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest distance between 1 and 2 (distance is 1.1468545161613708 ):\n",
      "Прошло почти четыре года с тех пор, как Илон Маск запустил свой Tesla Roadster в космос на ракете Falcon Heavy компании SpaceX. Сейчас электромобиль находится на таком расстоянии от Земли, что Марс ему куда ближе родной планеты. Вскоре после запуска электрокара в космос был запущен и сайт Where is Roadster? для отслеживания его перемещения с помощью данных NASA. Ресурс указывает, что Roadster удаляется от Земли со скоростью 6 005 км/ч, в то время как к Марсу он движется со скоростью 27 955 км/ч. До Красной планеты осталось менее 320 миллионов км, а общий \"пробег\" машины почти достиг 3 млрд километров. Этого достаточно, чтобы проехать по всем дорогам мира 49,5 раз. В беседе CNN с астрономом Джонатаном Макдауэллом из Гарвард-Смитсоновского центра астрофизики выяснилось, что Tesla, вероятно, всё ещё цела, но могла быть повреждена ударами метеоритов. Интересно, что астрономы не наблюдали электромобиль в свои телескопы с марта 2018 года, а профессор астрофизики Университета Торонто Ханно Рейн заявил, что изучение его траектории не имеет особой научной ценности. В конце концов, это не более чем дорогой космический мусор.\n",
      "-\n",
      "Tesla преодолела более трех миллиардов километров. В космосе Электромобилю для этого потребовалось четыре года. С тех пор, как Илон Маск запустил красную Tesla Roadster в космос на ракете Falcon Heavy своей компании SpaceX, прошло четыре года. В настоящее время электрокар находится уже ближе к Марсу, чем к Земле — от нашей планеты он удалился на 377 миллионов километров. После запуска родстера в космос был запущен сайт Where is Roadster? для отслеживания его перемещения при помощи NASA. Согласно официальным данным, всего Tesla преодолела уже более 3,2 миллиарда километров.\n"
     ]
    }
   ],
   "source": [
    "ed.sort(key=lambda v:v[2])\n",
    "print(f'The smallest distance between {ed[0][0]} and {ed[0][1]} (distance is {ed[0][2]} ):')\n",
    "print(data[ed[0][0]])\n",
    "print('-')\n",
    "print(data[ed[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee19503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest distance between texts 0 and 3 (distance is 1.4111379334456944 ):\n",
      "Электрокар Tesla Roadster Илона Маска, запущенный в сторону Марса в начале 2018 года, постепенно разрушается в открытом космосе. К таким выводам пришли эксперты издания LiveScience. По их данным, автомобиль уже полностью лишился окраски кузова, кожаных сидений и покрышек.По словам химика из университета Индианы и эксперта по пластмассам и органическим молекулам Уильяма Кэрролла, в будущем от машины останутся лишь каркас и стекла. На молекулы распадутся и все пластиковые детали электрокара. Месяц назад машину уже официально признали космическим мусором — автомобиль был внесен в соответствующий каталог всех космических объектов искусственного происхождения (GCAT). Напомним, электрокар Tesla Roadster первого поколения, принадлежащий главе компаний Tesla и SpaceX Илону Маску, отправили в космос на ракете-носителе Falcon Heavy. Машина выступила в качестве балластной нагрузки, призванной продемонстрировать грузоподъемность космического корабля. За рулем автомобиля сидел манекен в скафандре, которого назвали Starman, а при запуске ракеты из динамиков авто играла песня Дэвида Боуи Space Oddity.\n",
      "-\n",
      "«Газпром» снизит поставки газа через «Северный поток-1» из-за задержки с ремонтом агрегатов компанией Siemens, сообщила госкомпания. «Поставки газа в газопровод «Северный поток» в настоящее время могут быть обеспечены в объеме до 100 млн куб. м в сутки (при плановом объеме 167 млн куб. м в сутки)», — заявили в компании. В «Газпроме» пояснили, что сокращение поставок связано с ситуацией на компрессорной станции (КС) «Портовая». По данным оператора, немецкая компания Siemens несвоевременно вернула газоперекачивающие агрегаты из ремонта. Кроме того, проблемы связаны с выработкой межремонтного ресурса газоперекачивающих агрегатов и выявленными техническими неисправностями двигателей (получено предписание Ростехнадзора о временном запрете деятельности).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Biggest distance between texts {ed[-1][0]} and {ed[-1][1]} (distance is {ed[-1][2]} ):')\n",
    "print(data[ed[-1][0]])\n",
    "print('-')\n",
    "print(data[ed[-1][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30edf334",
   "metadata": {},
   "source": [
    "***\n",
    "Now let's try using GloVe word embeddings. For simplicity, we will consider each document as one sentence and work with doc vectors. Because I use articles written in Russian, I use word embeddings from Navec (https://natasha.github.io/navec/) that were trained using news articles. \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe41b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "nv = Navec.load('data/embeddings/navec_news_v1_1B_250K_300d_100q.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d148544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(map(vectorizer.build_tokenizer(),data))\n",
    "#min_token_len = 3\n",
    "tokens = [[t.lower() for t in doc_toks if t in vectorizer.vocabulary_] for doc_toks in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430791ca",
   "metadata": {},
   "source": [
    "***\n",
    "Extract from the article:\n",
    "Now we have to represent every document as a single vector. We can either average or sum over every word vector and convert every 64X300 representation into a 300-dimensional representation. But averaging or summing over all the words would lose the semantic and contextual meaning of the documents. Different lengths of the documents would also have an adverse effect on such operations.\n",
    "\n",
    "One better way of doing this could be taking a weighted average of word vectors using the tf-idf weights. This can handle the variable length problem to a certain extent but cannot keep the semantic and contextual meaning of words. After doing that we can use the pairwise distances to calculate similar documents as we did in the tf-idf model.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36ee2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75848a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sz = nv.pq.dim\n",
    "tfidf_df = pd.DataFrame(tfidf_mat.toarray())\n",
    "docs_emb = np.zeros((len(data), emb_sz))\n",
    "for i in range(len(data)):\n",
    "    for t in tokens[i]:\n",
    "        if t in nv.vocab:\n",
    "            docs_emb[i] += nv[t] * tfidf_df[vectorizer.vocabulary_[t]][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42d9c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_emb_norm = normalize(docs_emb, axis=1, norm='l2')\n",
    "cosi = [] #cosine similarity\n",
    "ed = [] #euclidean distance\n",
    "for r1, r2 in itertools.combinations(range(docs_emb.shape[0]), 2):\n",
    "    c = np.dot(docs_emb_norm[r1], docs_emb_norm[r2].T)\n",
    "    d = np.sqrt(np.power(docs_emb[r2] - docs_emb[r1], 2).sum())\n",
    "    cosi.append((r1, r2, c))\n",
    "    ed.append((r1, r2, d))\n",
    "#cosine_similarity(docs_emb)\n",
    "#euclidean_distances(docs_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396bae28",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c5b7d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar texts are 1 and 2 (cosine similarity is 0.822083303190346 ):\n",
      "Least similar texts are 1 and 3 (cosine similarity is 0.4568089726027239 ):\n",
      "The smallest distance between 0 and 1 (distance is 10.304522040145553 ):\n",
      "Biggest distance between texts 2 and 3 (distance is 17.376559808309153 ):\n"
     ]
    }
   ],
   "source": [
    "cosi.sort(key=lambda v:v[2], reverse=True)\n",
    "print(f'Most similar texts are {cosi[0][0]} and {cosi[0][1]} (cosine similarity is {cosi[0][2]} ):')\n",
    "print(f'Least similar texts are {cosi[-1][0]} and {cosi[-1][1]} (cosine similarity is {cosi[-1][2]} ):')\n",
    "print(f'The smallest distance between {ed[0][0]} and {ed[0][1]} (distance is {ed[0][2]} ):')\n",
    "print(f'Biggest distance between texts {ed[-1][0]} and {ed[-1][1]} (distance is {ed[-1][2]} ):')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv2",
   "language": "python",
   "name": "nlpenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

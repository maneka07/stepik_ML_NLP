{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7af587e2",
   "metadata": {},
   "source": [
    "<font size=6>\n",
    "Using the standard modele torch.nn.RNN to generate a text. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b005e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6855b",
   "metadata": {},
   "source": [
    "<font size=6>\n",
    "Preprocess the data.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31279de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/author_quotes.txt', 'rt', newline='\\n') as f:\n",
    "    text_data = f.readlines()\n",
    "text_data = [q.rstrip('\\n') for q in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce9f938d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab has 85 unique characters\n"
     ]
    }
   ],
   "source": [
    "id2char = list(set(' '.join(text_data)))\n",
    "char2id = {v: i for i, v in enumerate(id2char)}\n",
    "PAD_VALUE = char2id[' ']\n",
    "MAX_SEQ_LEN = max([len(l) for l in text_data])\n",
    "print(f\"Vocab has {len(id2char)} unique characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c60808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text_data, char2id, pad_value, max_seq_len):\n",
    "    '''Now create input vectors and target vectors. \n",
    "    From input sequences delete the last character, we do not need to feed it into \n",
    "    the network. For the target sequence remove the first character, because we start predicting\n",
    "    from the second character in the sequence'''\n",
    "    text_in = [list(l)[:-1] for l in text_data]\n",
    "    text_out = [list(l)[1:] for l in text_data]\n",
    "    num_samples = len(text_data)\n",
    "    #vectorize\n",
    "    input_vect = torch.full((num_samples, max_seq_len), pad_value, dtype=torch.long)\n",
    "    target_vect = torch.full((num_samples, max_seq_len), pad_value, dtype=torch.long)\n",
    "    for i, line in enumerate(text_in):\n",
    "        for j, ch in enumerate(line):\n",
    "            input_vect[i][j] = char2id[ch]\n",
    "        target_vect[i][:-1] = input_vect[i][1:] \n",
    "        target_vect[i][len(text_out[i])-1] = char2id[text_out[i][-1]]\n",
    "    return input_vect, target_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c087f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vect, target_vect = vectorize(text_data, char2id, char2id[' '], MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d02b6ce",
   "metadata": {},
   "source": [
    "<font size=6>\n",
    "RNN model\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5a1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class charRNN(nn.Module):\n",
    "    def __init__(self, char_vocab_len, emb_size=16, num_layers=1, hid_state_size=64):\n",
    "        super().__init__()\n",
    "        self.num_rnn_layers = num_layers\n",
    "        self.hid_state_size = hid_state_size\n",
    "        self.emb = nn.Embedding(char_vocab_len, emb_size)\n",
    "        self.rnn = nn.RNN(emb_size, hid_state_size, num_layers=num_layers, batch_first=True)\n",
    "        self.out = nn.Linear(hid_state_size, char_vocab_len)\n",
    "    \n",
    "    def forward(self, x, prev_h=None):\n",
    "        batch_sz, seq_len = x.shape\n",
    "        x = self.emb(x)  # batch_sz x MAX_SEQ_LEN x emb_sz\n",
    "        if prev_h == None:\n",
    "            #init h0\n",
    "            prev_h = self.get_init_state(batch_sz)\n",
    "        features, hidden = self.rnn(x, prev_h) #features of size batch_sz x MAX_SEQ_LEN x hid_state_size      \n",
    "        logits = self.out(features)  #batch_sz x MAX_SEQ_LEN x char_vocab_len\n",
    "        logits = pred.view(batch_sz*seq_len, -1)\n",
    "        return logits, hidden\n",
    "    def get_init_state(self, batch_size):\n",
    "        return torch.zeros(self.num_rnn_layers, batch_size, self.hid_state_size)\n",
    "\n",
    "ch_model = charRNN(len(char2id), num_layers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e603e6",
   "metadata": {},
   "source": [
    "<font size=6>\n",
    "Helper functions\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f64cc90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, input_vect, target_vect, lr=0.01, n_epochs=10, batch_size=128, max_num_batches=0):\n",
    "    import time\n",
    "    import matplotlib.pyplot as plt\n",
    "    from IPython.display import clear_output\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if batch_size > len(input_vect):\n",
    "        batch_size = len(input_vect)\n",
    "    #remove the last character from input (nothing to predict for it) and \n",
    "    #the first character from output (since the first char we predict is the second character\n",
    "    #in the sequence)\n",
    "    dataset = torch.utils.data.TensorDataset(input_vect,\n",
    "                                             target_vect)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    loss_fun = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    history = []\n",
    "    for epoch in range(n_epochs):\n",
    "        t_beg = time.perf_counter()\n",
    "        mean_loss = 0\n",
    "        nbatches = 0\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            model.zero_grad()\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            pred, _ = model(batch_x)\n",
    "            loss = loss_fun(pred, batch_y.view(-1))\n",
    "            mean_loss += float(loss)\n",
    "            nbatches +=1\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            if max_num_batches and nbatches == max_num_batches:\n",
    "                break\n",
    "        print(f\"epoch {epoch} loss {mean_loss/nbatches}, epoch time {time.perf_counter()-t_beg}\")\n",
    "     # visualizing training process\n",
    "        history.append(mean_loss)\n",
    "    plt.plot(history,label='loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "            \n",
    "    return model\n",
    "\n",
    "def predict_char(model, chars, char2id, id2char, temperature, hidden = None):\n",
    "    vect_data = torch.tensor([[char2id[ch] for ch in chars]])\n",
    "    #print(vect_data.shape)\n",
    "    #pass the seed sequence first to get the hidden state\n",
    "    logits, hidden = model(vect_data, prev_h=hidden) \n",
    "    p_next = nn.functional.softmax(logits / temperature, dim=-1).data.numpy()[-1, :]\n",
    "    #choose next token with probability distribution\n",
    "    char_ind = np.random.choice(len(char2id), p=p_next)\n",
    "    return id2char[char_ind], hidden\n",
    "\n",
    "def generate_sequence(model, char2id, id2char, seed_seq = \"hi\", seq_len = MAX_SEQ_LEN, temperature=1.0):\n",
    "    if seq_len <= len(seed_seq):\n",
    "        return seed_seq \n",
    "    model.eval()\n",
    "    #first pass the seed sequence except for the last char through RNN to get the last hidden state\n",
    "    chars_vect = torch.tensor([[char2id[ch] for ch in seed_seq[:-1]]], dtype=torch.long)\n",
    "    _, hidden = model(chars_vect)\n",
    "    #now pass the last character from the list and start generating next characters\n",
    "    chars = list(seed_seq)\n",
    "    for _ in range(seq_len - len(seed_seq)):\n",
    "        next_char, hidden = predict_char(model, chars[-1], char2id, id2char, temperature, hidden=hidden)\n",
    "        chars.append(next_char)\n",
    "    return ''.join(chars)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb38167c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 1.0698981297016144, epoch time 49.68379279999999\n",
      "epoch 1 loss 0.776541730761528, epoch time 44.90064270000002\n",
      "epoch 2 loss 0.7072157955169678, epoch time 46.150713999999994\n",
      "epoch 3 loss 0.6666237545013428, epoch time 48.47750550000001\n",
      "epoch 4 loss 0.6493605411052704, epoch time 45.35900369999996\n",
      "epoch 5 loss 0.6259592980146408, epoch time 47.39145289999999\n",
      "epoch 6 loss 0.6123793566226959, epoch time 43.0065745\n",
      "epoch 7 loss 0.6056795251369477, epoch time 44.937648300000035\n",
      "epoch 8 loss 0.590649824142456, epoch time 44.054019100000005\n",
      "epoch 9 loss 0.5859751641750336, epoch time 44.6017425\n",
      "epoch 10 loss 0.5811545383930207, epoch time 43.59181530000001\n",
      "epoch 11 loss 0.5817364001274109, epoch time 47.05569400000002\n",
      "epoch 12 loss 0.576561582684517, epoch time 44.972512800000004\n",
      "epoch 13 loss 0.5730481198430062, epoch time 45.21457829999997\n",
      "epoch 14 loss 0.5708137321472168, epoch time 46.55987469999991\n",
      "epoch 15 loss 0.5668684715032577, epoch time 45.83301140000003\n",
      "epoch 16 loss 0.5600125443935394, epoch time 44.73045830000001\n",
      "epoch 17 loss 0.5666816198825836, epoch time 45.97059289999993\n",
      "epoch 18 loss 0.5665000981092453, epoch time 58.31590720000008\n",
      "epoch 19 loss 0.560018302500248, epoch time 46.81250449999993\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ch_model.load_state_dict(torch.load('./models/RNN-2022-07-05.model', map_location=torch.device('cpu')))\n",
    "ch_model = train(ch_model, input_vect, target_vect, lr=0.01, n_epochs=20, max_num_batches=100)\n",
    "#torch.save(ch_model.state_dict(), './models/char_rnn.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "022a4687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(ch_model.state_dict(), './models/char_rnn.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7fb40f1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "themm of the a thind to who have love. I like or f\n"
     ]
    }
   ],
   "source": [
    "print(generate_sequence(ch_model, char2id, id2char, seed_seq=\"the\", seq_len=50, temperature=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8136411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conclusion: it generates some gibberish. This can probably be improved by getting a larger dataset,\n",
    "    more training time and maybe using better e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv2",
   "language": "python",
   "name": "nlpenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
